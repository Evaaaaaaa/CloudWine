{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import logging\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TfidfTrainer:\n",
    "    def __init__(self):\n",
    "        self.tf_transformer = None\n",
    "        self.text_vectors = None\n",
    "\n",
    "    # Train TF-IDF model\n",
    "    def train(self, corpus):\n",
    "        logger.info(\"Training model\")\n",
    "        tf = TfidfVectorizer(analyzer='word', ngram_range=(1,2), stop_words = \"english\", lowercase = True, max_features = 50000)\n",
    "        self.tf_transformer = tf.fit(corpus)\n",
    "        self.text_vectors = tf.fit_transform(corpus).toarray()\n",
    "\n",
    "    # Returns the trained sentence vectors\n",
    "    def get_vectors(self):\n",
    "        return self.text_vectors\n",
    "\n",
    "    # Save the model in pickle format\n",
    "    def save(self, path):\n",
    "        logger.info(\"Saving model to %s\", path)\n",
    "        # Save TfidfVectoriser vocab\n",
    "        with open(path + '/tfidf_transform.pkl', \"wb\") as pickleFile:\n",
    "            pickle.dump(self.tf_transformer, pickleFile)\n",
    "        # Save corpus text vectors\n",
    "        logger.info(\"Saving vectors to %s\", path)\n",
    "        with open(path +  '/tfidf_matrix.pkl', \"wb\") as pickleFile:\n",
    "            pickle.dump(self.text_vectors, pickleFile)\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, dir):\n",
    "        self.dir = dir\n",
    "        self.df_raw = self.__read_data__()\n",
    "        self.df = self.__process_data__()\n",
    "\n",
    "    # Returns the dataset corpus\n",
    "    def get_corpus(self):\n",
    "        return self.df['description'].to_list()\n",
    "\n",
    "    # Returns corpus labels\n",
    "    def get_labels(self):\n",
    "        return self.df['variety_region']\n",
    "\n",
    "    # Returns dataset\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    # Saves the dataframe as a pickle\n",
    "    def save(self, dir):\n",
    "        columns = ['title', 'description', 'points', 'price', 'variety', 'region_1']\n",
    "        self.df[columns].to_pickle(dir + '/tfidf_metadata.pkl')\n",
    "\n",
    "    # Read in dataframe\n",
    "    def __read_data__(self):\n",
    "        path = self.dir + '/sample.csv'\n",
    "        # path = self.dir + '/sample_10000.csv'\n",
    "        # path = self.dir + '/winemag-data-130k-v2.csv'\n",
    "        logger.info(\"Loading data from %s\", path)\n",
    "        if not (os.path.isfile(path)):\n",
    "            raise ValueError(path)\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "    # Process dataframe\n",
    "    def __process_data__(self):\n",
    "        # Remove nans from important columns\n",
    "        df = self.df_raw[(self.df_raw['variety'].notna()) & (self.df_raw['region_1'].notna())]\n",
    "        df = df.reset_index(drop=True)\n",
    "        # Create new feature variety + region_1\n",
    "        df['variety_region'] = df[['variety', 'region_1']].agg('-'.join, axis=1)\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data_dir': '../data/raw',\n",
    "    'model_dir': '../models'\n",
    "}\n",
    "\n",
    "# Read training data\n",
    "dataset = Dataset(args['data_dir'])\n",
    "corpus = dataset.get_corpus()\n",
    "\n",
    "# Train TF-IDF model\n",
    "model = TfidfTrainer()\n",
    "model.train(corpus)\n",
    "\n",
    "# Save run\n",
    "model.save(args['model_dir'])\n",
    "dataset.save(args['model_dir'])\n",
    "\n",
    "# Validate\n",
    "# valid = Validation()\n",
    "# valid.plot_pca(model.get_vectors(), dataset.get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.get_vectors()\n",
    "df = dataset.get_df()\n",
    "y = df['variety_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1296e1670>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "feat_cols = [ 'embedding'+str(i) for i in range(x.shape[1]) ]\n",
    "df_embed = pd.DataFrame(x,columns=feat_cols)\n",
    "df_embed['y'] = y\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(x)\n",
    "df_embed['pca-one'] = pca_result[:,0]\n",
    "df_embed['pca-two'] = pca_result[:,1]\n",
    "\n",
    "df_embed['size'] = 0\n",
    "df_embed.loc[df_embed['y'] != 'unknown','size'] = 10\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"pca-one\", y=\"pca-two\",\n",
    "    hue=\"y\",\n",
    "    data=df_embed,\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudwine",
   "language": "python",
   "name": "cloudwine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
